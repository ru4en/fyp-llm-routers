\chapter{Conclusions and Future Work}
\label{ch:con}



\section{Summary of Findings}
\label{sec:summary-of-findings}

The results of the evaluation indicate that the Router library is effective in selecting the appropriate agent or tool for a given task. Although it significantly depends on how much context is provided. The tool router outperformed the agent router, this was prodominantly due to the fact that the prompts \textit{hinted} at the tool to be used. The agent router was less effective, this could be improve implement the suggestions made in the previous section. Fine-tuning the model on a dataset specifically designed for routing tasks to a specific topic and asigning the topic to the agent could be one way to improve the performance of the agent router, Although much tinkering is needed to improve this.


\section{Evaluation of the Router}
\label{sec:evaluation-of-the-router}


\section{Critical Analysis of the Results}
\label{sec:results-critical-analysis}

This research has shown that NLI is a promising approach for routing tasks. although the results are promising, there are several improvements and questions that need to be addressed. As discussed in the previously, successfully fine-tuning the models specifically for routing tasks could significantly improve the performance of the router. Another area of improvement is to explore the use of few-shot or reinforcement learning to refine the router's decision making on the fly. This could help the router adapt to new tasks and improve its performance over time.

\subsection{Flaws in synthetic prompt generation}
\label{sec:results-flaws-in-synthetic-prompt-generation}

The synthetic prompt generation although at the beginning of the project was a good idea, it was not the best approach to evaluate the router. The prompts were not realistic and did not reflect the complexity of real-world tasks. This limited the effectiveness of the evaluation and made it difficult to draw meaningful conclusions about the router's performance. Future work should focus on collecting genuine user queries and tracking router decisions to uncover blind spots. My one suggestion would be to use something like the \texttt{OpenWebUIs} rating system to collect real user queries and track router decisions. This would provide a more realistic evaluation of the router's performance and help identify areas for improvement.


\subsection{Limitations in Model Fine-tuning Approach}
\label{sec:results-limitations-in-model-fine-tuning-approach}

The fine-tuning approach used in this research was limited by the availability of high-quality datasets for routing tasks. The lack of large, annotated datasets made it challenging to train the models effectively. Additionally, the lack of adequate computational resources limited the ability to experiment with different model architectures and training strategies. Future work should focus on developing larger, more diverse datasets for routing tasks and exploring more advanced model architectures and training techniques.

\subsection{Future improvements to the Router Library}
\label{sec:results-future-improvements-to-the-router-library}

The Router library is a promising tool for routing tasks, but there are several areas for improvement.

First, the library could benefit from more extensive documentation and examples to help users understand how to use it effectively. This would make it easier for developers to integrate the library into their applications and take advantage of its capabilities.

Second, the library could be extended to support more advanced routing techniques, such as hierarchical routing or ensemble approaches. This would allow users to experiment with different routing strategies and find the best approach for their specific use cases.

Third, the library could be improved by adding support for more advanced model architectures and training techniques. This would allow users to experiment with different models and find the best approach for their specific use cases.

Finally, the library could benefit from more extensive testing and evaluation to ensure its robustness and reliability. Currently, the library has no automated tests or benchmarks, which makes it difficult to recommend it for production use. Adding automated tests and benchmarks would help ensure that the library is reliable.

\section{Recommendations for Future Work}
\label{sec:results-recommendations}

Building on these results, we recommend several avenues for further research. First, expanding the evaluation with real user studies would yield more robust insights into practical effectiveness. For example, collecting genuine user queries and tracking router decisions would help uncover blind spots. Integrating analytics could enable continuous monitoring of router accuracy over time.

Second, advancing the router model itself could improve performance. Possible strategies include: (a) few-shot or reinforcement learning to refine the routerâ€™s decision-making on-the-fly, (b) hierarchical routing, where a lightweight intent classifier first filters queries and only invokes the LLM router when needed, and (c) developing ensemble approaches (e.g. combining GPT-4 with a smaller local model for quick decisions). The Arize best practices note that starting simple and evolving based on metrics is advisable. Investigating these alternatives could provide a more comprehensive understanding of the landscape.

Finally, Using a fine-tuned model for the agent router could significantly improve its performance. This would involve training the model on a dataset of routing tasks, where the model learns to select the most appropriate agent for each task. This would require a significant amount of data and computational resources, but it could lead to an improvement in the performance of the agent router.




\section{Conclusion}
\label{sec:results-conclusion}
In conclusion, the initial results demonstrate that Router using NLI models can be effective in selecting the appropriate agent or tool for a given task with a high degree of accuracy and retevelely low latency. The tool router outperformed the agent router, indicating that more work is needed to improve the agent router's performance.

