[{"id":"rubens_model_router","user_id":"4227cc1d-492b-4ab3-8f2b-a7cc537e0e29","name":"Agent Router","type":"pipe","content":"\"\"\"\ntitle: Agent Router\nauthor: Ruben Lopes (@ru4en)\ndescription: |\n  This is a simple agent router that uses a zero-shot classification model to route queries to the appropriate agent or tool.\n  It uses the Hugging Face Transformers library for the zero-shot classification model.\n  The router can be used to route queries to different agents or tools based on their descriptions.\n  The router can be used in a pipeline with other components.\nrequirements: pydantic, requests, git+https://github.com/ru4en/llm_routers.git\nversion: 1.0.0\n\"\"\"\n\nfrom llm_routers import AgentRouter\nfrom pydantic import BaseModel, Field\nimport logging\nfrom typing import (\n    Union,\n    Generator,\n    Iterator,\n    List,\n    Dict,\n    Optional,\n    Callable,\n    Awaitable,\n    Any,\n    Tuple,\n)\n\nfrom transformers import pipeline\n\ntasklist = [\n    {\n        \"model\": \"Email Assistant\",\n        \"tasks\": \"Generate email responses, summarize emails, extract information from emails\",\n    },\n    {\n        \"model\": \"Code Assistant\",\n        \"tasks\": \"Generate code snippets, debug code, explain code functionality\",\n    },\n    {\n        \"model\": \"Text Summarizer\",\n        \"tasks\": \"Summarize long texts, extract key points from articles, create concise summaries\",\n    },\n    {\n        \"model\": \"Chatbot\",\n        \"tasks\": \"Engage in conversation, answer questions, provide information\",\n    },\n    {\n        \"model\": \"Sentiment Analysis\",\n        \"tasks\": \"Analyze sentiment of text, classify text as positive/negative/neutral\",\n    },\n]\n\n\ndef generate_chat_completion(query: str) -> str:\n    \"\"\"\n    Simulate a chat completion response for the given query.\n    This is a placeholder function and should be replaced with actual logic.\n    \"\"\"\n    # Simulated response\n    return f\"Simulated response for query: {query}\"\n\n\nclass Pipe:\n    class Valves(BaseModel):\n        model: str = Field(\n            \"facebook/bart-large-mnli\",\n            description=\"The model to use for the zero-shot classification task.\",\n        )\n        n: int = Field(3, description=\"The number of models to return.\")\n        threshold: float = Field(0.08, description=\"The threshold for model selection.\")\n        classification: List[Dict[str, str]] = Field(\n            tasklist,\n            description=\"A list of models and their associated tasks.\",\n        )\n\n    def __init__(self):\n        self.valves = self.Valves()\n        self.classifier = None\n        # Initialize the classifier only when needed to avoid loading it at startup\n\n    def pipe(self, body: dict):\n        \"\"\"\n        Process the incoming request by routing to the best model.\n\n        This function:\n        1. Extracts the user query from the body\n        2. Routes the query to find the best matching model\n        3. Updates the body with the selected model ID\n        4. Returns the updated body\n\n        Args:\n            body: Input data containing the user query\n\n        Returns:\n            Updated body with the selected model ID\n        \"\"\"\n        try:\n            # Extract the user query from messages\n            query = \"\"\n            if \"messages\" in body and len(body[\"messages\"]) > 0:\n                # Get the most recent user message\n                for msg in reversed(body[\"messages\"]):\n                    if msg.get(\"role\") == \"user\" and \"content\" in msg:\n                        query = msg[\"content\"]\n                        break\n\n            if not query:\n                logging.warning(\"No user query found in the request\")\n                return body  # Return original body if no query found\n\n            if self.classifier is None:\n                self.classifier = AgentRouter(\n                    agents={\n                        task[\"model\"]: task[\"tasks\"]\n                        for task in self.valves.classification\n                    },\n                    model_name=self.valves.model,\n                    top_n=self.valves.n,\n                    threshold=self.valves.threshold,\n                )\n\n            # Log the incoming query\n            logging.debug(f\"Incoming query: {query}\")\n            # Route the query to find the best matching model\n            results = self.classifier.route_query(query)\n            logging.debug(f\"Routing results: {results}\")\n\n            if results:\n                # Get the best model ID (highest score)\n                best_model_id, score = results[0]\n                logging.info(\n                    f\"Selected model '{best_model_id}' with confidence {score:.4f} for query: {query[:50]}...\"\n                )\n\n                # Update the body with the selected model\n                body[\"model\"] = best_model_id\n\n                # Optionally add routing info to the body for transparency\n                body[\"_routing\"] = {\n                    \"selected_model\": best_model_id,\n                    \"confidence\": score,\n                    \"all_matches\": [\n                        {\"model\": model, \"score\": round(score, 4)}\n                        for model, score in results\n                    ],\n                }\n            else:\n                logging.warning(f\"No suitable model found for query: {query[:50]}...\")\n\n            response = generate_chat_completion(query)\n            return f\"\"\"\n            {body.get('model', 'No model selected')}: {response}\n            Agent Router Pipe Debug Info:\n            ==========================\n            Query: {query}\n            Selected Agent: {body.get('model')}\n            Tools: {body.get('tools')}\n            Confidence: {body.get('_routing', {}).get('confidence')}\n            All Matches: {body.get('_routing', {}).get('all_matches')}\n            Response: {response}\n            ==========================\n            \"\"\"\n\n        except Exception as e:\n            logging.error(f\"Error in model router pipe: {e}\")\n            # Return original body on error\n            return f\"\"\"\n            Error in model router pipe: {e}\n            Please check the logs for more details.\n            \n            body: {body}\n            \"\"\"\n\n    def pipes(self):\n        \"\"\"\n        Generate the list of models for the Open WebUI interface.\n\n        Returns:\n            List of dictionaries with model information\n        \"\"\"\n        model_router_info = {\n            \"id\": \"model_router\",\n            \"name\": \"ðŸ§  Auto Agent Router\",\n            \"description\": \"Automatically selects the best model for your task\",\n        }\n\n        # Return the router as a single model option\n        return [model_router_info]\n","meta":{"description":"Agent Router","manifest":{"title":"Agent Router","author":"Ruben Lopes (@ru4en)","description":"|","requirements":"pydantic, requests, git+https://github.com/ru4en/llm_routers.git","version":"1.0.0"}},"is_active":true,"is_global":false,"updated_at":1746400545,"created_at":1745879882}]