\begin{thebibliography}{xx}

\harvarditem[Bender et~al.]{Bender, Gebru, McMillan-Major \harvardand\
  Shmitchell}{2021}{bender2021dangers}
Bender, E.~M., Gebru, T., McMillan-Major, A. \harvardand\ Shmitchell, S.
  \harvardyearleft 2021\harvardyearright , `On the dangers of stochastic
  parrots: Can language models be too big?', {\em Proceedings of the 2021 ACM
  Conference on Fairness, Accountability, and Transparency} pp.~610--623.

\harvarditem[Hu et~al.]{Hu, Bieker, Li, Jiang, Keigwin, Ranganath, Keutzer
  \harvardand\ Upadhyay}{2024}{hu2024routerbenchbenchmarkmultillmrouting}
Hu, Q.~J., Bieker, J., Li, X., Jiang, N., Keigwin, B., Ranganath, G., Keutzer,
  K. \harvardand\ Upadhyay, S.~K.  \harvardyearleft 2024\harvardyearright ,
  `Routerbench: A benchmark for multi-llm routing system'.
\newline\harvardurl{https://arxiv.org/abs/2403.12031}

\harvarditem[Jiang et~al.]{Jiang, Xu, Gao, Sun, Liu, Dwivedi-Yu, Yang, Callan
  \harvardand\ Neubig}{2023}{jiang2023activeretrievalaugmentedgeneration}
Jiang, Z., Xu, F.~F., Gao, L., Sun, Z., Liu, Q., Dwivedi-Yu, J., Yang, Y.,
  Callan, J. \harvardand\ Neubig, G.  \harvardyearleft 2023\harvardyearright ,
  `Active retrieval augmented generation'.
\newline\harvardurl{https://arxiv.org/abs/2305.06983}

\harvarditem[Kumar et~al.]{Kumar, Roh, Naseh, Karpinska, Iyyer, Houmansadr
  \harvardand\ Bagdasarian}{2025}{kumar2025overthinkslowdownattacksreasoning}
Kumar, A., Roh, J., Naseh, A., Karpinska, M., Iyyer, M., Houmansadr, A.
  \harvardand\ Bagdasarian, E.  \harvardyearleft 2025\harvardyearright ,
  `Overthink: Slowdown attacks on reasoning llms'.
\newline\harvardurl{https://arxiv.org/abs/2502.02542}

\harvarditem[Ong et~al.]{Ong, Almahairi, Wu, Chiang, Wu, Gonzalez, Kadous
  \harvardand\ Stoica}{2025}{ong2025routellmlearningroutellms}
Ong, I., Almahairi, A., Wu, V., Chiang, W.-L., Wu, T., Gonzalez, J.~E., Kadous,
  M.~W. \harvardand\ Stoica, I.  \harvardyearleft 2025\harvardyearright ,
  `Routellm: Learning to route llms with preference data'.
\newline\harvardurl{https://arxiv.org/abs/2406.18665}

\harvarditem[Schick et~al.]{Schick, Dwivedi-Yu, Dessì, Raileanu, Lomeli,
  Zettlemoyer, Cancedda \harvardand\
  Scialom}{2023}{schick2023toolformerlanguagemodelsteach}
Schick, T., Dwivedi-Yu, J., Dessì, R., Raileanu, R., Lomeli, M., Zettlemoyer,
  L., Cancedda, N. \harvardand\ Scialom, T.  \harvardyearleft
  2023\harvardyearright , `Toolformer: Language models can teach themselves to
  use tools'.
\newline\harvardurl{https://arxiv.org/abs/2302.04761}

\harvarditem[Strubell et~al.]{Strubell, Ganesh \harvardand\
  McCallum}{2019}{strubell2019energypolicyconsiderationsdeep}
Strubell, E., Ganesh, A. \harvardand\ McCallum, A.  \harvardyearleft
  2019\harvardyearright , `Energy and policy considerations for deep learning
  in nlp'.
\newline\harvardurl{https://arxiv.org/abs/1906.02243}

\harvarditem[Varangot-Reille et~al.]{Varangot-Reille, Bouvard, Gourru,
  Ciancone, Schaeffer \harvardand\
  Jacquenet}{2025}{varangotreille2025doingimplementingrouting}
Varangot-Reille, C., Bouvard, C., Gourru, A., Ciancone, M., Schaeffer, M.
  \harvardand\ Jacquenet, F.  \harvardyearleft 2025\harvardyearright , `Doing
  more with less -- implementing routing strategies in large language
  model-based systems: An extended survey'.
\newline\harvardurl{https://arxiv.org/abs/2502.00409}

\harvarditem[Wang et~al.]{Wang, Liu, Xu, Liang, Chen, He, Song, Yu, Li, Zhang,
  Wang, Tu, Mi \harvardand\ Yu}{2025}{wang2025thoughtsplaceunderthinkingo1like}
Wang, Y., Liu, Q., Xu, J., Liang, T., Chen, X., He, Z., Song, L., Yu, D., Li,
  J., Zhang, Z., Wang, R., Tu, Z., Mi, H. \harvardand\ Yu, D.  \harvardyearleft
  2025\harvardyearright , `Thoughts are all over the place: On the
  underthinking of o1-like llms'.
\newline\harvardurl{https://arxiv.org/abs/2501.18585}

\end{thebibliography}
